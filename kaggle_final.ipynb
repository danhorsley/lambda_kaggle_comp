{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - Water Pumps in Tanzania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "A very interesting project to work on, though I have resisted the temptation to aquire a lot of domain knowledge which I will probably never use again, and focus more on fine tuning decent models, which is a skill I am sure I will use again and again in the future.\n",
    "This is quite a large data frame with almost 60,000 rows and 40 features.  Many of the features are identical or almost identical (i.e. 'quantity' and 'quantity group','water quality' and 'quality group', 'payment' and 'payment type')\n",
    "One thing that stands out on first inspection is that region code and region don't always match up, so I iterated through the whole datframe and found the most likely true matches to create a mapping dictionary, which I hard coded for later notebook as the process was fairly time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('C:/Users/danie/Desktop/train_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the hardcoded dictionary I mentioned earlier and a function to map it to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict={'Arusha': 2, 'Dar es Salaam': 7, 'Dodoma': 1, 'Iringa': 11, 'Kagera': 18, 'Kigoma': 16, 'Kilimanjaro': 3,\n",
    "             'Lindi': 80, 'Manyara': 21, 'Mara': 20, 'Mbeya': 12, 'Morogoro': 5, 'Mtwara': 90, 'Mwanza': 19, 'Pwani': 6, \n",
    "             'Rukwa': 15, 'Ruvuma': 10, 'Shinyanga': 17, 'Singida': 13, 'Tabora': 14, 'Tanga': 4}\n",
    "def clean_region(frame):\n",
    "    frame['region_code']=frame['region'].map(region_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_region(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bit of code is far less complicated than it looks!  There are a lot of missing longitude/latitude coordinates that you can map to the average for each region.  I used a custom postcode combing area code and region code to try and be more exact, and failing that used a region average.  I also applied this to construction year and considered doing it for population however the reasoning was far less clear for these.  Construction year made no difference to the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['my_area_code']=100*df['region_code']+df['district_code']\n",
    "df_long_lat=df[['region_code','my_area_code','longitude','latitude','gps_height','construction_year']].copy()\n",
    "df_long_lat=df_long_lat[df_long_lat['longitude']!=0]\n",
    "df_ll=df_long_lat.groupby(['my_area_code'])[['longitude','latitude','gps_height']].mean()\n",
    "longitude_dict=df_ll['longitude'].to_dict()\n",
    "latitude_dict=df_ll['latitude'].to_dict()\n",
    "height_dict=df_ll['gps_height'].to_dict()\n",
    "df_ll2=df_long_lat.groupby(['region_code'])[['longitude','latitude','gps_height']].mean()\n",
    "longitude_dict2=df_ll2['longitude'].to_dict()\n",
    "latitude_dict2=df_ll2['latitude'].to_dict()\n",
    "height_dict2=df_ll2['gps_height'].to_dict()\n",
    "\n",
    "df_cy=df_long_lat[df_long_lat['construction_year']!=0].copy()\n",
    "df_cyg=df_cy.groupby(['my_area_code'])[['construction_year']].median()\n",
    "cy_dict=df_cyg['construction_year'].to_dict()\n",
    "df_cyg2=df_cy.groupby(['region_code'])[['construction_year']].median()\n",
    "cy_dict2=df_cyg2['construction_year'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_long_lat(frame):\n",
    "    frame['my_area_code']=100*frame['region_code']+frame['district_code']\n",
    "    frame['latitude_est']=frame['my_area_code'].map(latitude_dict)\n",
    "    frame['longitude_est']=frame['my_area_code'].map(longitude_dict)\n",
    "    frame['latitude_est2']=frame['region_code'].map(latitude_dict2)\n",
    "    frame['longitude_est2']=frame['region_code'].map(longitude_dict2)\n",
    "    frame['gps_height_est']=frame['my_area_code'].map(height_dict)\n",
    "    frame['gps_height_est2']=frame['region_code'].map(height_dict2)\n",
    "    frame['cy_est']=frame['my_area_code'].map(cy_dict)\n",
    "    frame['cy_est2']=frame['region_code'].map(cy_dict2)\n",
    "    frame['new_longitude']=np.where(frame['longitude']!=0,frame['longitude'],frame['longitude_est'])\n",
    "    frame['new_longitude']=np.where(frame['new_longitude'].isna(),frame['longitude_est2'],frame['new_longitude'])\n",
    "    frame['new_latitude']=np.where(frame['latitude']!=-2e-08,frame['latitude'],frame['latitude_est'])\n",
    "    frame['new_latitude']=np.where(frame['new_latitude'].isna(),frame['latitude_est2'],frame['new_latitude'])\n",
    "    frame['new_gpsh']=np.where(frame['longitude']!=0,frame['gps_height'],frame['gps_height_est'])\n",
    "    frame['new_gpsh']=np.where(frame['new_gpsh'].isna(),frame['gps_height_est2'],frame['new_gpsh'])\n",
    "    frame['new_cy']=np.where(frame['construction_year']!=0,frame['construction_year'],frame['cy_est'])\n",
    "    frame['new_cy']=np.where(frame['new_cy'].isna(),frame['cy_est2'],frame['new_cy'])\n",
    "    frame['new_cy']=np.where(frame['new_cy'].isna(),0,frame['new_cy'])\n",
    "    frame=frame.drop(['my_area_code','latitude_est','longitude_est','latitude_est2','longitude_est2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_long_lat(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to turn dates to oridnal and create a month feature.  the year feature had zero impact on the final score so I left it out of the final computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time(frame):\n",
    "    frame['date_recorded']=pd.to_datetime(frame['date_recorded'],format='%Y-%m-%d')\n",
    "    dates_list=list(frame['date_recorded'])\n",
    "    month_list=[x.month for x in dates_list]\n",
    "    year_list=[x.year for x in dates_list]\n",
    "    frame['month']=month_list\n",
    "    frame['date_recorded']=(pd.to_datetime(frame['date_recorded'])).apply(lambda x: x.toordinal())\n",
    "    frame['year']=year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a stripped down list of features.  We excluded any categorical feature with high dimensionality (i.e. greater than 30) and included the new calculations for longitude/latitude/height and construction year.  We also removed some column that after we first ran classifiers on them the features were shown to be not very meaningful (e.g. 'num_private' and 'recorded_by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['basin','scheme_management',\n",
    " 'extraction_type_group','extraction_type_class','month','payment',\n",
    " 'quantity','source',\n",
    " 'waterpoint_type','amount_tsh','new_gpsh','new_longitude','new_latitude',\n",
    " 'population','new_cy','district_code','region_code',\n",
    "         'date_recorded','permit','public_meeting'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we make a processing pipeline to ordinal encode categories, impute missing data and scale things down for the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.copy()[features]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(),SimpleImputer(),RobustScaler())\n",
    "\n",
    "preprocessor.fit(X)\n",
    "\n",
    "def process_data(frame):\n",
    "    X=frame.copy()[features]\n",
    "    X = preprocessor.transform(X)\n",
    "    X=pd.DataFrame(X,columns=features)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=process_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the target.  See below what we mentioned earlier, i.e. the percentage weights of the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.543081\n",
       "0    0.384242\n",
       "2    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.read_csv('C:/Users/danie/Desktop/train_labels.csv')\n",
    "y=y.drop('id',axis=1)\n",
    "y_dict={'functional':1,'non functional':0,'functional needs repair':2}\n",
    "y['status_group']=y['status_group'].map(y_dict)\n",
    "y['status_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first randomized search.  I initially ran RandomForest as a second baseline (after majority class) as it's quick to run and usually gives a solid score to try and beat on later attempts.  However the first result (above 0.79 accuracy) exceed my wildest expectations so we iterated a few more times.  This first random search is for 'entropy' style, I found it sufficiently different from 'gini' that we can combine them later to a positive effect with a voting classifier.  There is a fair amount of overfitting here, but it is difficult to avoid and hopefully is balanced out by combining models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  8.2min remaining:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=True),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000187CCCD49B0>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000187CCCD4E80>, 'warm_start': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions_f = {\n",
    "    'n_estimators':randint(100,140),\n",
    "    'max_depth':randint(16,23),\n",
    "   'warm_start':[True,False]\n",
    "}\n",
    "\n",
    "search_f=RandomizedSearchCV(\n",
    "      estimator=RandomForestClassifier(criterion='entropy',warm_start=True,oob_score=True,n_jobs=-1,random_state=42),\n",
    "      param_distributions=param_distributions_f,\n",
    "      n_iter=10,\n",
    "      scoring='accuracy',\n",
    "      n_jobs=-1,\n",
    "      cv=3,\n",
    "      verbose=10,\n",
    "      return_train_score=True)\n",
    "\n",
    "search_f.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters were 19 max depth and 138 estimators, however if you look just below with 17 max depth and 119 estimators suffers much less from over fitting (92 train vs almost identical .8075 test mean) so we should go for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_warm_start</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.886129</td>\n",
       "      <td>1.167405</td>\n",
       "      <td>3.090958</td>\n",
       "      <td>0.148688</td>\n",
       "      <td>19</td>\n",
       "      <td>138</td>\n",
       "      <td>False</td>\n",
       "      <td>{'max_depth': 19, 'n_estimators': 138, 'warm_s...</td>\n",
       "      <td>0.808232</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.806364</td>\n",
       "      <td>0.807525</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961742</td>\n",
       "      <td>0.961338</td>\n",
       "      <td>0.962424</td>\n",
       "      <td>0.961835</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.789549</td>\n",
       "      <td>1.940356</td>\n",
       "      <td>1.505718</td>\n",
       "      <td>0.230003</td>\n",
       "      <td>17</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>{'max_depth': 17, 'n_estimators': 119, 'warm_s...</td>\n",
       "      <td>0.808030</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.806313</td>\n",
       "      <td>0.807306</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926970</td>\n",
       "      <td>0.930202</td>\n",
       "      <td>0.931616</td>\n",
       "      <td>0.929596</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6      43.886129      1.167405         3.090958        0.148688   \n",
       "1      67.789549      1.940356         1.505718        0.230003   \n",
       "\n",
       "  param_max_depth param_n_estimators param_warm_start  \\\n",
       "6              19                138            False   \n",
       "1              17                119            False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "6  {'max_depth': 19, 'n_estimators': 138, 'warm_s...           0.808232   \n",
       "1  {'max_depth': 17, 'n_estimators': 119, 'warm_s...           0.808030   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "6           0.807980           0.806364         0.807525        0.000828   \n",
       "1           0.807576           0.806313         0.807306        0.000726   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "6                1            0.961742            0.961338   \n",
       "1                2            0.926970            0.930202   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "6            0.962424          0.961835         0.000448  \n",
       "1            0.931616          0.929596         0.001945  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_f.cv_results_).sort_values(by='rank_test_score').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run another randomized search, again for randomized forest, though this time using 'gini'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  4.5min remaining:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000187CCCFEA20>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000187CCCFE6D8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions_g = {\n",
    "    'n_estimators':randint(110,140),\n",
    "    'max_depth':randint(17,23)#,\n",
    "}\n",
    "\n",
    "search_g=RandomizedSearchCV(\n",
    "      estimator=RandomForestClassifier(criterion='gini',oob_score=True,n_jobs=-1,random_state=42),\n",
    "      param_distributions=param_distributions_g,\n",
    "      n_iter=10,\n",
    "      scoring='accuracy',\n",
    "      n_jobs=-1,\n",
    "      cv=3,\n",
    "      verbose=10,\n",
    "      return_train_score=True)\n",
    "\n",
    "search_g.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we are going to go for the less over fit estimators which have almost the same score, i.e 18 max depth and 128 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.045108</td>\n",
       "      <td>0.437356</td>\n",
       "      <td>1.943506</td>\n",
       "      <td>0.155792</td>\n",
       "      <td>19</td>\n",
       "      <td>132</td>\n",
       "      <td>{'max_depth': 19, 'n_estimators': 132}</td>\n",
       "      <td>0.808636</td>\n",
       "      <td>0.810051</td>\n",
       "      <td>0.805960</td>\n",
       "      <td>0.808215</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956035</td>\n",
       "      <td>0.957222</td>\n",
       "      <td>0.957551</td>\n",
       "      <td>0.956936</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.742795</td>\n",
       "      <td>0.380573</td>\n",
       "      <td>1.712485</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>{'max_depth': 18, 'n_estimators': 128}</td>\n",
       "      <td>0.809899</td>\n",
       "      <td>0.808131</td>\n",
       "      <td>0.806566</td>\n",
       "      <td>0.808199</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>2</td>\n",
       "      <td>0.940682</td>\n",
       "      <td>0.941692</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.941902</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8      32.045108      0.437356         1.943506        0.155792   \n",
       "4      32.742795      0.380573         1.712485        0.282989   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params  \\\n",
       "8              19                132  {'max_depth': 19, 'n_estimators': 132}   \n",
       "4              18                128  {'max_depth': 18, 'n_estimators': 128}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "8           0.808636           0.810051           0.805960         0.808215   \n",
       "4           0.809899           0.808131           0.806566         0.808199   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "8        0.001696                1            0.956035            0.957222   \n",
       "4        0.001362                2            0.940682            0.941692   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "8            0.957551          0.956936         0.000651  \n",
       "4            0.943333          0.941902         0.001093  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_g.cv_results_).sort_values(by='rank_test_score').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we choose the ones with signifigantly less overfitting\n",
    "rf_1=RandomForestClassifier(max_depth=17,n_estimators=119,criterion='entropy',\n",
    "                            warm_start=True,oob_score=True,n_jobs=-1,random_state=42)\n",
    "rf_2=estimator=RandomForestClassifier(max_depth=18,n_estimators=128,criterion='gini',oob_score=True,n_jobs=-1,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import and run a voting classifier on the two random forest to increase their score a little....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([20.89718366, 24.75527811, 25.40743756, 29.03135443, 30.03475785]),\n",
       " 'score_time': array([0.75126696, 0.73615026, 0.73218727, 0.86477447, 0.8470912 ]),\n",
       " 'test_score': array([0.81727127, 0.810622  , 0.81085859, 0.81010101, 0.81107931]),\n",
       " 'train_score': array([0.92973337, 0.92922831, 0.93045034, 0.93030303, 0.93350448])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc_rf=VotingClassifier(estimators=[('rf_1', rf_1), ('rf_2', rf_2)], voting='soft',weights=[1,1])\n",
    "cv_results_rf = cross_validate(vc_rf, X, y.values.ravel(), cv=5,return_train_score=True)\n",
    "cv_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined score is higher at almost 0.812 accuracy  and seems to be very consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119864354433937"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_rf['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine two XGB classifiers.  One slow and one fast,i.e. one with low number of estimators but high learning rate and one with a high number of estimators and low learning rate.  They had broadly comparable results.  These took a very long time to run compared to the random forest so I did it in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_short=XGBClassifier(max_depth=8,n_estimators=105,learning_rate=0.6,objective= 'multi:softmax',\n",
    "                              num_class=3,n_jobs=-1,random_state=42)\n",
    "xgb_long=XGBClassifier(max_depth=8,n_estimators=1000,learning_rate=0.05,objective= 'multi:softmax',\n",
    "                              num_class=3,n_jobs=-1,random_state=42)\n",
    "\n",
    "vc_xgb=VotingClassifier(estimators=[('xgbs', xgb_short), ('xgbl', xgb_long)], voting='soft',weights=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine all the voting classifiers and run a final cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_final=VotingClassifier(estimators=[('vc_rf', vc_rf), ('vc_xgb', vc_xgb)], voting='soft',weights=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_final = cross_validate(vc_final, X, y.values.ravel(), cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([405.80336785, 406.77339315, 408.47739768, 407.10822773,\n",
       "        482.96674323]),\n",
       " 'score_time': array([ 8.75763083,  8.68955112,  8.7667799 ,  9.94503951, 10.18921399]),\n",
       " 'test_score': array([0.81836546, 0.81323121, 0.81405724, 0.80976431, 0.81057417]),\n",
       " 'train_score': array([0.93337402, 0.93547844, 0.93533249, 0.93583754, 0.93491436])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small improvement....barely worth it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813198477300918"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_final['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our submission using the code below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('vc_rf', VotingClassifier(estimators=[('rf_1', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=17, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=...sample=1))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft',\n",
       "         weights=[1, 1]))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft',\n",
       "         weights=[1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_final.fit(X,y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict={v: k for k, v in y_dict.items()}\n",
    "def subber(frame,y_pred):\n",
    "    temp_frame=pd.DataFrame(frame.copy()['id'])\n",
    "    temp_frame['status_group']=y_pred\n",
    "    temp_frame['status_group']=temp_frame['status_group'].map(reverse_dict)\n",
    "\n",
    "    return temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('C:/Users/danie/Desktop/test_features.csv')\n",
    "clean_region(test)\n",
    "clean_long_lat(test)\n",
    "create_time(test)\n",
    "X_test=test[features].copy()\n",
    "X_test=process_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new=vc_final.predict(X_test)\n",
    "sub_df10 = subber(test,y_pred_new)\n",
    "sub_df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df10.to_csv('C:/Users/danie/Desktop/sub_csv10',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is that!  this last submission received a score of 0.81933.  not the best, but should be the least susceptible to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Bokeh Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import row, column\n",
    "from bokeh.models import CustomJS, Slider\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource, curdoc\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, LogColorMapper, ContinuousTicker, CategoricalTicker, BasicTicker, ColorBar,\n",
    "    Range1d, PanTool, WheelZoomTool, BoxSelectTool\n",
    ")\n",
    "from bokeh.models.mappers import ColorMapper, LinearColorMapper, CategoricalColorMapper\n",
    "from bokeh.palettes import Viridis5\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.io import output_file, output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf=df.copy()[['basin','scheme_management',\n",
    " 'extraction_type_group','extraction_type_class','month','payment',\n",
    " 'quantity','source',\n",
    " 'waterpoint_type','amount_tsh','new_gpsh','new_longitude','new_latitude',\n",
    " 'population','new_cy','district_code','region_code',\n",
    "         'date_recorded']]\n",
    "plotdf['status_group']=y['status_group'].map(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'functional':1,'non functional':0,'functional needs repair':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_options = GMapOptions(lat=39.5, lng=-98.5, map_type=\"roadmap\",zoom=3)\n",
    "plot = GMapPlot(x_range=Range1d(), y_range=Range1d(), map_options=map_options)\n",
    "plot.api_key = \"AIzaSyBFBYwhS6OLCNv4mhi-4TxF-euwYpsJZQI\"\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=plotdf['new_latitude'].tolist(),\n",
    "        lon=plotdf['new_longitude'].tolist(),\n",
    "        status=['functional','non functional','functional needs repair'],\n",
    "        color=bees['bee type code'].tolist()\n",
    "    ))\n",
    "\n",
    "source2 = ColumnDataSource(\n",
    "    data=dict(\n",
    "         lat=plotdf['new_latitude'].tolist(),\n",
    "        lon=plotdf['new_longitude'].tolist(),\n",
    "        year=bees['year'].tolist(),\n",
    "        color=bees['bee type code'].tolist()\n",
    "    ))\n",
    "\n",
    "color_mapper = LinearColorMapper(palette=Category20[12])\n",
    "\n",
    "mapper = CategoricalColorMapper(palette=Category20[20], factors=bee_names)\n",
    "\n",
    "circle=Circle(x=\"lon\", y=\"lat\", size=10, fill_color={'field': 'color', 'transform': color_mapper}, fill_alpha=0.5, line_color=None) #\n",
    "\n",
    "plot.add_glyph(source, circle)\n",
    "\n",
    "callback = CustomJS(args=dict(source1=source,source2=source2), code='''\n",
    "\n",
    "// JavaScript code goes here \n",
    "var data = source1.data;\n",
    "var data2 = source2.data;\n",
    "var Y = yrr.value;\n",
    "var lon = data['lon']\n",
    "var lat = data['lat']\n",
    "var color = data['color']\n",
    "// iterate through rows of data source and see if each satisfies some constraint\n",
    "for (var i = 0; i < source1.get_length(); i++){\n",
    "    if (source1.data['year'][i] == Y){\n",
    "        lon[i] = data2['lon'][i];\n",
    "    } else {\n",
    "        lon[i] = 0;\n",
    "    }}\n",
    "\n",
    "source1.change.emit();\n",
    "''')\n",
    "  \n",
    "year_slider = Slider(start=1945, end=2011, value=1965, step=1,\n",
    "                    title=\"Year\",callback=callback)\n",
    "callback.args[\"yrr\"] = year_slider\n",
    "\n",
    "layout = row(\n",
    "    plot,\n",
    "    column(year_slider),\n",
    ")\n",
    "\n",
    "color_bar = ColorBar(color_mapper=color_mapper, ticker=BasicTicker(),\n",
    "                    label_standoff=12, border_line_color=None, location=(0,0))\n",
    "\n",
    "#color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(),\n",
    "   #                  label_standoff=12, border_line_color=None, location=(0,0))\n",
    "\n",
    "plot.add_layout(color_bar, 'right')\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
